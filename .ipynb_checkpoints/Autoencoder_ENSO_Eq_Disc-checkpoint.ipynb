{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "import cmocean\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy.fft as fft\n",
    "import matplotlib.ticker as ticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU,Conv2d\n",
    "from itertools import *\n",
    "\n",
    "def pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_CNN_normalize(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,data_in,data_out,device = \"cuda\"):\n",
    "\n",
    "        super().__init__()\n",
    "        num_inputs = data_in.shape[1]\n",
    "        num_outputs = data_out.shape[1]\n",
    "        self.size = data_in.shape[0]\n",
    "        \n",
    "        data_in = np.nan_to_num(data_in)\n",
    "        data_out = np.nan_to_num(data_out)\n",
    "        \n",
    "        std_data = np.nanstd(data_in,axis=(0,2,3))\n",
    "        mean_data = np.nanmean(data_in,axis=(0,2,3)) \n",
    "        std_label = np.nanstd(data_out,axis=(0,2,3))\n",
    "        mean_label = np.nanmean(data_out,axis=(0,2,3))\n",
    "        \n",
    "        for i in range(num_inputs):\n",
    "            data_in[:,i,:,:] = (data_in[:,i,:,:,] - mean_data[i])/std_data[i]\n",
    "        \n",
    "        for i in range(num_outputs):\n",
    "            data_out[:,i,:,:] = (data_out[:,i,:,:] - mean_label[i])/std_label[i]\n",
    "            \n",
    "        data_in = torch.from_numpy(data_in).type(torch.float32).to(device=device)\n",
    "        data_out = torch.from_numpy(data_out).type(torch.float32).to(device=device)        \n",
    "        \n",
    "\n",
    "        std_dict = {'s_in':std_data,'s_out':std_label,'m_in':mean_data, 'm_out':mean_label}\n",
    "            \n",
    "        self.input = data_in\n",
    "        self.output = data_out\n",
    "        \n",
    "        self.norm_vals = std_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_in = self.input[idx]\n",
    "        label = self.output[idx]\n",
    "        return data_in, label\n",
    "    \n",
    "# basic training loop \n",
    "# model = the model you are training\n",
    "# train_loader = dataloader from the training dataset, see below \n",
    "# test_loader = dataloader from the test dataset, see below \n",
    "# num_epochs = number of update steps of the model. In each step, the model will see the full dataset\n",
    "# loss = loss function chosen of the form (scalar = loss(pred,true))\n",
    "# optim = optimizer that will update your network\n",
    "\n",
    "def train(model, train_loader, test_loader, num_epochs, loss_fn, optim):\n",
    "    # Set up the loss and the optimizer\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(data)\n",
    "\n",
    "            loss = loss_fn(outs, label) # no train_mask!\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        for data, label in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outs = model(data)\n",
    "            loss_val = loss_fn(outs, label) # no train_mask!\n",
    "        if epoch%2==0:    \n",
    "            print(f'[Epoch {epoch+1}/{num_epochs}] Loss: {loss} | Val Loss: {loss_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_block(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,num_in = 2, num_out = 2,kernel_size = 3, num_layers=1, pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = num_in\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(torch.nn.Conv2d(num_in,num_out,kernel_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        for _ in range(num_layers-1):\n",
    "            layers.append(torch.nn.Conv2d(num_out,num_out,kernel_size))\n",
    "            layers.append(torch.nn.ReLU())              \n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "        return fts\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.size = size\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        self.linear_size = int(self.N_out*(size[0]/(2**len(ch_width[:-1])))*(size[1]/(2**len(ch_width[:-1]))))\n",
    "\n",
    "        # going down\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(embed_dim,\n",
    "                                self.linear_size))\n",
    "        layers.append(nn.Unflatten(1,(self.N_out,int(size[0]/(2**len(ch_width[:-1]))),\n",
    "                                      int(size[1]/(2**len(ch_width[:-1]))))))\n",
    "        layers.append(nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        ch_width.reverse()\n",
    "        for a,b in pairwise(ch_width[:-1]):\n",
    "            layers.append(Conv_block(a,b,pad=pad))\n",
    "            layers.append(nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        layers.append(Conv2d(b,self.N_in,kernel_size))\n",
    "\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "            \n",
    "        return fts \n",
    "    \n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        self.size = size\n",
    "        self.linear_size = int(self.N_out*(size[0]/(2**len(ch_width[:-1])))*(size[1]/(2**len(ch_width[:-1]))))\n",
    "        \n",
    "        # going down\n",
    "        layers = []\n",
    "        for a,b in pairwise(ch_width):\n",
    "            layers.append(Conv_block(a,b,pad=pad))\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        layers.append(nn.Linear(self.linear_size,\n",
    "                                embed_dim))        \n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:            \n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            \n",
    "            if isinstance(l,nn.Linear):\n",
    "                fts = fts.flatten(start_dim=1)\n",
    "            fts= l(fts)\n",
    "            \n",
    "        return fts  \n",
    "    \n",
    "class Encoder_Decoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.encoder = Encoder(ch_width,embed_dim,size,kernel_size,pad)\n",
    "        self.decoder = Decoder(ch_width,embed_dim,size,kernel_size,pad)\n",
    "\n",
    "        # going down\n",
    "        layers = []\n",
    "\n",
    "        layers.append(self.encoder)\n",
    "        layers.append(self.decoder)\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "\n",
    "        return fts  \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_zarr(\"/scratch/as15415/Data/Emulation_Data/Global_Ocean_1deg.zarr/\")\n",
    "data = data[\"T\"]\n",
    "\n",
    "# data_1 = data.sel(xu_ocean = slice(35,80))\n",
    "# data_2 = data.sel(xu_ocean = slice(-280,-235))\n",
    "# data_2[\"xu_ocean\"] = data_2[\"xu_ocean\"].data+360\n",
    "# data = xr.concat([data_1,data_2],dim = \"xu_ocean\")\n",
    "# data = data.sel(yu_ocean = slice(-40,30))\n",
    "\n",
    "# Pacific\n",
    "\n",
    "\n",
    "data = data.sel(xu_ocean = slice(-208,-80),yu_ocean = slice(-31,30))\n",
    "\n",
    "wet =np.isnan(data[0])\n",
    "wet = xr.where(wet==0,np.nan,0)    \n",
    "wet = np.isnan(wet)\n",
    "wet = np.nan_to_num(wet.to_numpy())\n",
    "wet_bool = np.array(wet).astype(bool)\n",
    "\n",
    "locs = np.argwhere(wet_bool)\n",
    "\n",
    "Nx = data.xu_ocean.data.size\n",
    "Ny = data.yu_ocean.data.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = np.array(data.groupby('time.dayofyear').mean('time').compute())\n",
    "# clim = clim.mean(axis = [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_network = data[:7305].to_numpy()\n",
    "for i in range(7305):\n",
    "    day_yr = data.time.data[i].dayofyr-1\n",
    "    data_network[i] = data_network[i]- clim[day_yr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_network = np.expand_dims(data_network,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_CNN_normalize(data_network[:7305],data_network[:7305],device = device)\n",
    "val_data = data_CNN_normalize(data_network[5000:5500],data_network[5000:5500],device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may need to be kept smaller\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(val_data, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/45] Loss: 0.5524808168411255 | Val Loss: 0.7033915519714355\n",
      "[Epoch 3/45] Loss: 0.46940723061561584 | Val Loss: 0.6599351167678833\n",
      "[Epoch 5/45] Loss: 0.44795942306518555 | Val Loss: 0.6113085150718689\n",
      "[Epoch 7/45] Loss: 0.4190174639225006 | Val Loss: 0.5710746645927429\n",
      "[Epoch 9/45] Loss: 0.3959151804447174 | Val Loss: 0.5334755778312683\n",
      "[Epoch 11/45] Loss: 0.38100677728652954 | Val Loss: 0.5009045004844666\n",
      "[Epoch 13/45] Loss: 0.370576411485672 | Val Loss: 0.4733943045139313\n",
      "[Epoch 15/45] Loss: 0.3623778820037842 | Val Loss: 0.45063409209251404\n",
      "[Epoch 17/45] Loss: 0.35562872886657715 | Val Loss: 0.43140751123428345\n",
      "[Epoch 19/45] Loss: 0.35010528564453125 | Val Loss: 0.41525155305862427\n",
      "[Epoch 21/45] Loss: 0.3452613055706024 | Val Loss: 0.40187788009643555\n",
      "[Epoch 23/45] Loss: 0.340908020734787 | Val Loss: 0.3905557692050934\n",
      "[Epoch 25/45] Loss: 0.3368058204650879 | Val Loss: 0.3809729218482971\n",
      "[Epoch 27/45] Loss: 0.3329363167285919 | Val Loss: 0.37281233072280884\n",
      "[Epoch 29/45] Loss: 0.3294999301433563 | Val Loss: 0.3660418689250946\n",
      "[Epoch 31/45] Loss: 0.32642656564712524 | Val Loss: 0.3604981601238251\n",
      "[Epoch 33/45] Loss: 0.32354238629341125 | Val Loss: 0.3557969331741333\n",
      "[Epoch 35/45] Loss: 0.32096272706985474 | Val Loss: 0.3518196642398834\n",
      "[Epoch 37/45] Loss: 0.3186332881450653 | Val Loss: 0.3483763635158539\n",
      "[Epoch 39/45] Loss: 0.3164529502391815 | Val Loss: 0.3453655242919922\n",
      "[Epoch 41/45] Loss: 0.3143771290779114 | Val Loss: 0.34247174859046936\n",
      "[Epoch 43/45] Loss: 0.31245705485343933 | Val Loss: 0.33960530161857605\n",
      "[Epoch 45/45] Loss: 0.31060856580734253 | Val Loss: 0.3367404639720917\n"
     ]
    }
   ],
   "source": [
    "model = Encoder_Decoder([1,100,50,25],embed_dim=20)\n",
    "model = model.to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# define a loss function\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "# train the model (just pass in everthing that we have defined previously)\n",
    "# Note that your problems will likely require far fewer epochs for convergence\n",
    "\n",
    "train(model, train_loader, test_loader, 45, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.10 GiB (GPU 0; 44.48 GiB total capacity; 41.10 GiB already allocated; 3.12 GiB free; 41.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m embed_space \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m7305\u001b[39m,\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 4\u001b[0m     embed_space[:\u001b[38;5;241m2000\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      5\u001b[0m     embed_space[\u001b[38;5;241m2000\u001b[39m:\u001b[38;5;241m4000\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(train_data[\u001b[38;5;241m2000\u001b[39m:\u001b[38;5;241m4000\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 97\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, fts)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l,nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[1;32m     96\u001b[0m         fts \u001b[38;5;241m=\u001b[39m fts\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m     fts\u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fts\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m, in \u001b[0;36mConv_block.forward\u001b[0;34m(self, fts)\u001b[0m\n\u001b[1;32m     22\u001b[0m         fts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(fts,(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_pad,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_pad,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m),mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad)\n\u001b[1;32m     23\u001b[0m         fts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(fts,(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_pad,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_pad),mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     fts\u001b[38;5;241m=\u001b[39m \u001b[43ml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fts\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.10 GiB (GPU 0; 44.48 GiB total capacity; 41.10 GiB already allocated; 3.12 GiB free; 41.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "embed_space = torch.zeros((7305,20))\n",
    "\n",
    "with torch.no_grad():\n",
    "    embed_space[:2000] = model.encoder(train_data[:2000][0]).cpu()\n",
    "    embed_space[2000:4000] = model.encoder(train_data[2000:4000][0]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = np.linalg.svd(embed_space, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(U[:,1],\"r\",label = \"PC 2\")\n",
    "plt.plot(U[:,2],\"k\",label = \"PC 3\")\n",
    "plt.plot(U[:,0],\"b\",label = \"PC 1\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.from_numpy(V).type(torch.float32).to(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC1 = model.decoder(torch.unsqueeze(V[0,:],0)).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC1.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC2 = model.decoder(torch.unsqueeze(V[1,:],0)).cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC2.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC3 = model.decoder(torch.unsqueeze(V[2,:],0)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC3.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_reconstruct = model(train_data[:20][0]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,test_reconstruct[0].squeeze()*wet_bool,vmax = 2,vmin=-2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()\n",
    "plt.title(\"Reconstruction\",fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,train_data[0][0].cpu().squeeze()*wet_bool,vmax = 2,vmin=-2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()\n",
    "plt.title(\"Ground Truth\",fontsize=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC1 = (PC1- PC1.mean())/PC1.std()\n",
    "PC2 = (PC2- PC2.mean())/PC2.std()\n",
    "PC3 = (PC3- PC3.mean())/PC3.std()\n",
    "\n",
    "inpts = np.hstack((PC2,PC3))\n",
    "inpts_2 = np.hstack((PC1,PC3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est_gp = SymbolicRegressor(population_size=1000,\n",
    "                           generations=20, stopping_criteria=0.001,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1, feature_names= ['PC1',],\n",
    "                           max_samples=0.9, verbose=1,function_set= (['add','mul']),\n",
    "                           parsimony_coefficient=0.001, random_state=0,const_range=(-20,20),\n",
    "                          metric=\"mse\")\n",
    "est_gp.fit(PC1, PC2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = est_gp._program.export_graphviz()\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render('images/ex1_child', format='png', cleanup=True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.hstack((np.ones_like(PC1),PC1,PC1**2,PC1**3,PC1**4))\n",
    "c = np.linalg.lstsq(A,PC2)\n",
    "c = c[0]\n",
    "lin_reg_fit = np.matmul(A,c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PC2,\"k\",label = \"PC 2\")\n",
    "plt.plot(est_gp.predict(PC1),\"r\",label = \"Symbolic Regression\")\n",
    "plt.plot(lin_reg_fit,\"b\",label = \"Linear Regression\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est_gp = SymbolicRegressor(population_size=750,\n",
    "                           generations=4, stopping_criteria=0.0001,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1, feature_names= ['PC2','PC3'],\n",
    "                           max_samples=0.9, verbose=1,function_set= (['add','mul']),\n",
    "                           parsimony_coefficient=0.01, random_state=0,const_range=(-10,10))\n",
    "est_gp.fit(inpts, PC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = est_gp._program.export_graphviz()\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render('images/ex1_child', format='png', cleanup=True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.hstack((np.ones_like(PC3),PC3,PC3**2,PC3**3,PC3**4,\n",
    "               PC2,PC2**2,PC2**3,PC2**4,\n",
    "              PC2*PC3,PC2**2*PC3,PC2*PC3**2,PC2**2*PC3**2))\n",
    "c = np.linalg.lstsq(A,PC1)\n",
    "c = c[0]\n",
    "lin_reg_fit = np.matmul(A,c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PC2,\"k\",label = \"PC 2\")\n",
    "plt.plot(est_gp.predict(inpts),\"r\",label = \"Symbolic Regression\")\n",
    "plt.plot(lin_reg_fit,\"b\",label = \"Linear Regression\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "est_gp = SymbolicRegressor(population_size=750,\n",
    "                           generations=10, stopping_criteria=0.0001,\n",
    "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
    "                           p_hoist_mutation=0.05, p_point_mutation=0.1, feature_names= ['PC1','PC3'],\n",
    "                           max_samples=0.9, verbose=1,function_set= (['add','mul']),\n",
    "                           parsimony_coefficient=0.01, random_state=0,const_range=(-10,10),\n",
    "                          metric = \"mse\")\n",
    "est_gp.fit(inpts_2, PC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = est_gp._program.export_graphviz()\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render('images/ex1_child', format='png', cleanup=True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.hstack((np.ones_like(PC3),PC3,PC3**2,PC3**3,PC3**4,\n",
    "               PC1,PC1**2,PC1**3,PC1**4,\n",
    "              PC1*PC3,PC1**2*PC3,PC1*PC3**2,PC1**2*PC3**2))\n",
    "c = np.linalg.lstsq(A,PC2)\n",
    "c = c[0]\n",
    "lin_reg_fit = np.matmul(A,c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PC2,\"k\",label = \"PC 2\")\n",
    "plt.plot(est_gp.predict(inpts),\"r\",label = \"Symbolic Regression\")\n",
    "plt.plot(lin_reg_fit,\"b\",label = \"Linear Regression\")\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
