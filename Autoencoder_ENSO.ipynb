{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy as cart\n",
    "import cmocean\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import numpy.fft as fft\n",
    "import matplotlib.ticker as ticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU,Conv2d\n",
    "from itertools import *\n",
    "\n",
    "def pairwise(iterable):\n",
    "    # pairwise('ABCDEFG') --> AB BC CD DE EF FG\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_CNN_normalize(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,data_in,data_out,device = \"cuda\"):\n",
    "\n",
    "        super().__init__()\n",
    "        num_inputs = data_in.shape[1]\n",
    "        num_outputs = data_out.shape[1]\n",
    "        self.size = data_in.shape[0]\n",
    "        \n",
    "        data_in = np.nan_to_num(data_in)\n",
    "        data_out = np.nan_to_num(data_out)\n",
    "        \n",
    "        std_data = np.nanstd(data_in,axis=(0,2,3))\n",
    "        mean_data = np.nanmean(data_in,axis=(0,2,3)) \n",
    "        std_label = np.nanstd(data_out,axis=(0,2,3))\n",
    "        mean_label = np.nanmean(data_out,axis=(0,2,3))\n",
    "        \n",
    "        for i in range(num_inputs):\n",
    "            data_in[:,i,:,:] = (data_in[:,i,:,:,] - mean_data[i])/std_data[i]\n",
    "        \n",
    "        for i in range(num_outputs):\n",
    "            data_out[:,i,:,:] = (data_out[:,i,:,:] - mean_label[i])/std_label[i]\n",
    "            \n",
    "        data_in = torch.from_numpy(data_in).type(torch.float32).to(device=device)\n",
    "        data_out = torch.from_numpy(data_out).type(torch.float32).to(device=device)        \n",
    "        \n",
    "\n",
    "        std_dict = {'s_in':std_data,'s_out':std_label,'m_in':mean_data, 'm_out':mean_label}\n",
    "            \n",
    "        self.input = data_in\n",
    "        self.output = data_out\n",
    "        \n",
    "        self.norm_vals = std_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_in = self.input[idx]\n",
    "        label = self.output[idx]\n",
    "        return data_in, label\n",
    "    \n",
    "# basic training loop \n",
    "# model = the model you are training\n",
    "# train_loader = dataloader from the training dataset, see below \n",
    "# test_loader = dataloader from the test dataset, see below \n",
    "# num_epochs = number of update steps of the model. In each step, the model will see the full dataset\n",
    "# loss = loss function chosen of the form (scalar = loss(pred,true))\n",
    "# optim = optimizer that will update your network\n",
    "\n",
    "def train(model, train_loader, test_loader, num_epochs, loss_fn, optim):\n",
    "    # Set up the loss and the optimizer\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outs = model(data)\n",
    "\n",
    "            loss = loss_fn(outs, label) # no train_mask!\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        for data, label in test_loader:\n",
    "            outs = model(data)\n",
    "            loss_val = loss_fn(outs, label) # no train_mask!\n",
    "        if epoch%2==0:    \n",
    "            print(f'[Epoch {epoch+1}/{num_epochs}] Loss: {loss} | Val Loss: {loss_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_block(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,num_in = 2, num_out = 2,kernel_size = 3, num_layers=1, pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = num_in\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(torch.nn.Conv2d(num_in,num_out,kernel_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        for _ in range(num_layers-1):\n",
    "            layers.append(torch.nn.Conv2d(num_out,num_out,kernel_size))\n",
    "            layers.append(torch.nn.ReLU())              \n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "        return fts\n",
    "    \n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.size = size\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        self.linear_size = int(self.N_out*(size[0]/(2**len(ch_width[:-1])))*(size[1]/(2**len(ch_width[:-1]))))\n",
    "\n",
    "        # going down\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(embed_dim,\n",
    "                                self.linear_size))\n",
    "        layers.append(nn.Unflatten(1,(self.N_out,int(size[0]/(2**len(ch_width[:-1]))),\n",
    "                                      int(size[1]/(2**len(ch_width[:-1]))))))\n",
    "        layers.append(nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        ch_width.reverse()\n",
    "        for a,b in pairwise(ch_width[:-1]):\n",
    "            layers.append(Conv_block(a,b,pad=pad))\n",
    "            layers.append(nn.Upsample(scale_factor=2, mode='bilinear'))\n",
    "        layers.append(Conv2d(b,self.N_in,kernel_size))\n",
    "\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "            \n",
    "        return fts \n",
    "    \n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        self.size = size\n",
    "        self.linear_size = int(self.N_out*(size[0]/(2**len(ch_width[:-1])))*(size[1]/(2**len(ch_width[:-1]))))\n",
    "        \n",
    "        # going down\n",
    "        layers = []\n",
    "        for a,b in pairwise(ch_width):\n",
    "            layers.append(Conv_block(a,b,pad=pad))\n",
    "            layers.append(nn.MaxPool2d(2))\n",
    "        layers.append(nn.Linear(self.linear_size,\n",
    "                                embed_dim))        \n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:            \n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            \n",
    "            if isinstance(l,nn.Linear):\n",
    "                fts = fts.flatten(start_dim=1)\n",
    "            fts= l(fts)\n",
    "            \n",
    "        return fts  \n",
    "    \n",
    "class Encoder_Decoder(torch.nn.Module):\n",
    "    def __init__(self,ch_width,embed_dim = 20,size=[64,128],kernel_size = 3,pad = \"constant\"):\n",
    "        super().__init__()\n",
    "        self.N_in = ch_width[0]\n",
    "        self.N_out = ch_width[-1]\n",
    "        self.N_pad = int((kernel_size-1)/2)\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.encoder = Encoder(ch_width,embed_dim,size,kernel_size,pad)\n",
    "        self.decoder = Decoder(ch_width,embed_dim,size,kernel_size,pad)\n",
    "\n",
    "        # going down\n",
    "        layers = []\n",
    "\n",
    "        layers.append(self.encoder)\n",
    "        layers.append(self.decoder)\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "        self.num_steps = int(len(ch_width)-1)\n",
    "        \n",
    "        #self.layers = nn.ModuleList(layer)\n",
    "\n",
    "    def forward(self,fts):\n",
    "        for l in self.layers:\n",
    "            if isinstance(l,nn.Conv2d):\n",
    "                fts = torch.nn.functional.pad(fts,(self.N_pad,self.N_pad,0,0),mode=self.pad)\n",
    "                fts = torch.nn.functional.pad(fts,(0,0,self.N_pad,self.N_pad),mode=\"constant\")\n",
    "            fts= l(fts)\n",
    "\n",
    "        return fts  \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_zarr(\"/scratch/as15415/Data/Emulation_Data/Global_Ocean_1deg.zarr/\")\n",
    "data = data[\"T\"]\n",
    "\n",
    "# data_1 = data.sel(xu_ocean = slice(35,80))\n",
    "# data_2 = data.sel(xu_ocean = slice(-280,-235))\n",
    "# data_2[\"xu_ocean\"] = data_2[\"xu_ocean\"].data+360\n",
    "# data = xr.concat([data_1,data_2],dim = \"xu_ocean\")\n",
    "# data = data.sel(yu_ocean = slice(-40,30))\n",
    "\n",
    "# Pacific\n",
    "\n",
    "\n",
    "data = data.sel(xu_ocean = slice(-208,-80),yu_ocean = slice(-31,30))\n",
    "\n",
    "wet =np.isnan(data[0])\n",
    "wet = xr.where(wet==0,np.nan,0)    \n",
    "wet = np.isnan(wet)\n",
    "wet = np.nan_to_num(wet.to_numpy())\n",
    "wet_bool = np.array(wet).astype(bool)\n",
    "\n",
    "locs = np.argwhere(wet_bool)\n",
    "\n",
    "Nx = data.xu_ocean.data.size\n",
    "Ny = data.yu_ocean.data.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = np.array(data.groupby('time.dayofyear').mean('time').compute())\n",
    "# clim = clim.mean(axis = [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_network = data[:7000].to_numpy()\n",
    "for i in range(7000):\n",
    "    day_yr = data.time.data[i].dayofyr-1\n",
    "    data_network[i] = data_network[i]- clim[day_yr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_network = np.expand_dims(data_network,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_CNN_normalize(data_network[:7000],data_network[:7000],device = device)\n",
    "val_data = data_CNN_normalize(data_network[5000:5500],data_network[5000:5500],device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this may need to be kept smaller\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(val_data, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/45] Loss: 1.0065898895263672 | Val Loss: 0.709771454334259\n",
      "[Epoch 3/45] Loss: 0.7447910308837891 | Val Loss: 0.6599511504173279\n",
      "[Epoch 5/45] Loss: 0.6489663124084473 | Val Loss: 0.6281781792640686\n",
      "[Epoch 7/45] Loss: 0.5742431879043579 | Val Loss: 0.5783175826072693\n",
      "[Epoch 9/45] Loss: 0.5239560008049011 | Val Loss: 0.5354552268981934\n",
      "[Epoch 11/45] Loss: 0.4911409020423889 | Val Loss: 0.49963799118995667\n",
      "[Epoch 13/45] Loss: 0.4651571214199066 | Val Loss: 0.46951428055763245\n",
      "[Epoch 15/45] Loss: 0.4450254440307617 | Val Loss: 0.4443988800048828\n",
      "[Epoch 17/45] Loss: 0.42884501814842224 | Val Loss: 0.42498111724853516\n",
      "[Epoch 19/45] Loss: 0.41521507501602173 | Val Loss: 0.41000720858573914\n",
      "[Epoch 21/45] Loss: 0.40365996956825256 | Val Loss: 0.3982340395450592\n",
      "[Epoch 23/45] Loss: 0.39363908767700195 | Val Loss: 0.3888185918331146\n",
      "[Epoch 25/45] Loss: 0.3850368857383728 | Val Loss: 0.38095822930336\n",
      "[Epoch 27/45] Loss: 0.37745437026023865 | Val Loss: 0.3742803633213043\n",
      "[Epoch 29/45] Loss: 0.3706590235233307 | Val Loss: 0.36869528889656067\n",
      "[Epoch 31/45] Loss: 0.3644631505012512 | Val Loss: 0.36392149329185486\n"
     ]
    }
   ],
   "source": [
    "model = Encoder_Decoder([1,100,50,25],embed_dim=20)\n",
    "model = model.to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# define a loss function\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "# train the model (just pass in everthing that we have defined previously)\n",
    "# Note that your problems will likely require far fewer epochs for convergence\n",
    "\n",
    "train(model, train_loader, test_loader, 45, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    embed_space = model.encoder(train_data[:7000][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, V = np.linalg.svd(embed_space, full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(U[:,0],\"b\",label = \"PC 1\")\n",
    "plt.plot(U[:,1],\"r\",label = \"PC 2\")\n",
    "plt.plot(U[:,2],\"k\",label = \"PC 3\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.from_numpy(V).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC1 = model.decoder(torch.unsqueeze(V[0,:],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC1.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC2 = model.decoder(torch.unsqueeze(V[1,:],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC2.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    PC3 = model.decoder(torch.unsqueeze(V[2,:],0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('axes', labelsize=18)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=18)    # fontsize of the tick labels\n",
    "plt.rc('figure', titlesize=18)\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12,6),\n",
    "                        gridspec_kw={'width_ratios': [1], 'height_ratios': [1], 'wspace': 0.25,'hspace':.5},\n",
    "                       )\n",
    "\n",
    "plt.pcolor(data.xu_ocean,data.yu_ocean,PC3.cpu().squeeze()*wet_bool,vmax = .2,vmin=-.2,cmap=cmocean.cm.diff)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_new",
   "language": "python",
   "name": "torch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
